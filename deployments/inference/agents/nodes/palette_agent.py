"""Palette Agent — uses LLM tool calling to create palettes."""

import json

from langchain_ollama import ChatOllama
from langchain_core.messages import AIMessage, ToolMessage, SystemMessage, HumanMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode, tools_condition
import sys

sys.path.insert(0, "../")
from state import PaletteCandidate
from tools.colormind import fetch_palette
from tools.palette_utils import (
    palette_to_hex,
)
from tools.palette_formation import extract_colors_from_image, generate_palette_from_description, get_random_palette, parse_user_colors, create_palette_variation



PALETTE_SYSTEM = """You are a palette creation assistant. You have tools to create color palettes.

Pick the right tool based on what the user asks:
- User describes a mood/theme → generate_palette_from_description
- User gives hex codes or RGB values → parse_user_colors
- User wants colors from their image → extract_colors_from_image
- User wants a random palette → get_random_palette
- User wants to tweak existing palette → create_palette_variation

Call the appropriate tool. You may call multiple tools to give the user options."""

TOOLS = [
        extract_colors_from_image,
        generate_palette_from_description,
        get_random_palette,
        parse_user_colors,
        create_palette_variation,
    ]

def call_model(state: MessagesState):
    """Invoke the LLM with the current messages and bound tools."""
    model = ChatOllama(model="llama3.1:8b", temperature=0).bind_tools(TOOLS)
    response = model.invoke(state["messages"])
    return {"messages": [response]}


def build_palette_agent():
    """Build and compile the LangGraph agent.

    Returns the compiled StateGraph ready for .invoke().
    """
    graph = StateGraph(MessagesState)

    # Nodes
    graph.add_node("call_model", call_model)
    graph.add_node("tools", ToolNode(TOOLS))

    # Edges
    graph.add_edge(START, "call_model")
    graph.add_conditional_edges("call_model", tools_condition)
    graph.add_edge("tools", "call_model")

    agent = graph.compile()
    return agent


def palette_agent(state: dict) -> dict:
    """Outer-graph node: invokes the palette sub-graph and parses results."""
    last_msg = state["messages"][-1].content if state["messages"] else ""

    # Build and invoke the palette sub-graph
    agent = build_palette_agent()
    result = agent.invoke({
        "messages": [
            SystemMessage(content=PALETTE_SYSTEM),
            HumanMessage(content=last_msg),
        ]
    })

    # Parse ToolMessage results to collect palette candidates
    candidates: list[PaletteCandidate] = []
    for msg in result["messages"]:
        if not isinstance(msg, ToolMessage):
            continue
        try:
            parsed = json.loads(msg.content)
            if isinstance(parsed, list) and all(isinstance(p, dict) for p in parsed):
                # extract_colors_from_image returns [{colors, source}, ...]
                for p in parsed:
                    candidates.append({
                        "colors": p["colors"],
                        "source": p["source"],
                        "description": f"Extracted ({p['source']})",
                    })
            elif isinstance(parsed, list) and len(parsed) == 6:
                tool_name = getattr(msg, "name", "tool")
                candidates.append({
                    "colors": parsed,
                    "source": tool_name,
                    "description": f"Generated by {tool_name}",
                })
        except (json.JSONDecodeError, TypeError, KeyError):
            pass

    # Build response for the outer graph
    if candidates:
        selected = candidates[0]
        lines = ["Here are some palette options:\n"]
        for i, c in enumerate(candidates):
            hex_display = palette_to_hex(c["colors"])
            marker = " (selected)" if i == 0 else ""
            lines.append(
                f"{i+1}. **{c['description']}**{marker}\n   {hex_display}"
            )
        lines.append(
            "\nI've selected option 1. Say 'use 2' to pick another, "
            "'vary' for variations, or describe what you'd like to change."
        )
        return {
            "palette": selected["colors"],
            "palette_candidates": candidates,
            "palette_source": selected["source"],
            "error": None,
            "messages": [AIMessage(content="\n".join(lines))],
        }

    # Fallback — no tool produced results
    fallback = fetch_palette()
    if fallback:
        return {
            "palette": fallback,
            "palette_candidates": [{
                "colors": fallback,
                "source": "colormind_api",
                "description": "Auto-generated palette",
            }],
            "palette_source": "colormind_api",
            "error": None,
            "messages": [AIMessage(content=(
                "Here's an auto-generated palette:\n"
                + palette_to_hex(fallback)
            ))],
        }

    return {
        "error": "Could not generate any palettes",
        "messages": [AIMessage(content=(
            "I wasn't able to generate a palette. Could you try "
            "describing the colors you want in a different way?"
        ))],
    }
